Cleaned vs Dirty SÄ±nÄ±flandÄ±rma Projesi
ğŸ“„ Proje AÃ§Ä±klamasÄ±
Bu proje, Kaggle "Cleaned vs Dirty" veri seti kullanÄ±larak temiz (cleaned) ve kirli (dirty) gÃ¶rsellerin sÄ±nÄ±flandÄ±rÄ±lmasÄ±nÄ± hedeflemektedir. Temel bir Convolutional Neural Network (CNN) modeliyle, gÃ¶rsellerin sÄ±nÄ±f etiketlerine gÃ¶re ayrÄ±lmasÄ± saÄŸlanmÄ±ÅŸtÄ±r. Projede, veri artÄ±rma teknikleri ve sÄ±nÄ±f dengesizliÄŸine yÃ¶nelik optimizasyonlar uygulanarak doÄŸruluÄŸu yÃ¼ksek bir model geliÅŸtirilmiÅŸtir.

ğŸ“ Veri Seti
Projede kullanÄ±lan veri seti ÅŸu bileÅŸenlerden oluÅŸmaktadÄ±r:

EÄŸitim Verileri (Train Data): data/train/ dizininde bulunan, modelin Ã¶ÄŸrenmesi iÃ§in kullanÄ±lan gÃ¶rseller.
Test Verileri (Test Data): data/test/ dizininde bulunan, modelin baÅŸarÄ±mÄ±nÄ± Ã¶lÃ§mek iÃ§in kullanÄ±lan gÃ¶rseller.
Etiketler (Labels): GÃ¶rsellerin temiz ya da kirli olduÄŸunu belirten sÄ±nÄ±f etiketleri, data/sample_submission.csv dosyasÄ±nda yer alÄ±r.
Veri Seti Ã–zellikleri:
GÃ¶rseller Ã§eÅŸitli aÃ§Ä±lardan Ã§ekilmiÅŸ temiz ve kirli tabak gÃ¶rsellerini iÃ§ermektedir.
SÄ±nÄ±f dengesizliÄŸi gÃ¶zlemlenmiÅŸ ve bu durum veri artÄ±rma yÃ¶ntemleriyle ele alÄ±nmÄ±ÅŸtÄ±r.
ğŸ› ï¸ Proje AdÄ±mlarÄ±
1. Veri Ã–n Ä°ÅŸleme
Veri Ã¶n iÅŸleme aÅŸamasÄ±nda ÅŸu adÄ±mlar gerÃ§ekleÅŸtirilmiÅŸtir:

BoyutlandÄ±rma: GÃ¶rseller, CNN modeline uygun olacak ÅŸekilde 224x224 piksel boyutuna kÃ¼Ã§Ã¼ltÃ¼lmÃ¼ÅŸtÃ¼r.
Normalizasyon: GÃ¶rsel pikselleri, 0 ile 1 arasÄ±nda Ã¶lÃ§eklendirilmiÅŸtir.
Veri ArtÄ±rÄ±mÄ± (Augmentation):
DÃ¶ndÃ¼rme (Rotation): GÃ¶rseller rastgele belirli aÃ§Ä±larla dÃ¶ndÃ¼rÃ¼lmÃ¼ÅŸtÃ¼r.
Yatay Ã‡evirme (Horizontal Flip): GÃ¶rseller, ayna gÃ¶rÃ¼ntÃ¼sÃ¼ olarak Ã§evrilmiÅŸtir.
Renk YoÄŸunluÄŸu DeÄŸiÅŸtirme: GÃ¶rsellerdeki parlaklÄ±k ve kontrast deÄŸerleri deÄŸiÅŸtirilmiÅŸtir.
2. Model GeliÅŸtirme
Proje kapsamÄ±nda aÅŸaÄŸÄ±daki CNN modeli geliÅŸtirilmiÅŸtir:

Katmanlar:
Ä°ki adet evriÅŸim (convolution) ve maksimum havuzlama (max pooling) katmanÄ±.
Dropout ve aktivasyon fonksiyonlarÄ±yla (ReLU) desteklenmiÅŸ bir fully connected katman.
EÄŸitim AyrÄ±ntÄ±larÄ±:
Optimizer: Adam
KayÄ±p Fonksiyonu: Categorical Cross-Entropy
Epoch: 20
3. Model EÄŸitimi
Model eÄŸitimi sÄ±rasÄ±nda:

EÄŸitim ve doÄŸrulama verileri, %80-%20 oranÄ±nda ayrÄ±lmÄ±ÅŸtÄ±r.
Class Weights yÃ¶ntemiyle sÄ±nÄ±f dengesizliÄŸi optimize edilmiÅŸtir.
Modelin doÄŸruluk ve kayÄ±p deÄŸerleri her epoch sonunda kaydedilmiÅŸtir.
4. Model DeÄŸerlendirmesi
Model performansÄ± ÅŸu metriklerle analiz edilmiÅŸtir:

Accuracy (DoÄŸruluk): Modelin genel doÄŸruluk oranÄ± hesaplanmÄ±ÅŸtÄ±r.
Confusion Matrix: Temiz ve kirli sÄ±nÄ±flar iÃ§in doÄŸru/yanlÄ±ÅŸ tahminler gÃ¶rselleÅŸtirilmiÅŸtir.
SÄ±nÄ±flandÄ±rma Raporu: DoÄŸruluk, kesinlik (precision), hatÄ±rlama (recall) ve F1 skoru gibi detaylÄ± metrikler raporlanmÄ±ÅŸtÄ±r.
ğŸ† SonuÃ§lar
Genel DoÄŸruluk: %97.3
Confusion Matrix:
Modelin tahmin sonuÃ§larÄ± aÅŸaÄŸÄ±daki tabloda verilmiÅŸtir:
GerÃ§ek (Actual) \ Tahmin (Predicted)	Cleaned	Dirty
Cleaned	18	2
Dirty	18	706
Model, test verisi Ã¼zerinde sÄ±nÄ±flandÄ±rma baÅŸarÄ±sÄ±nÄ± etkili bir ÅŸekilde kanÄ±tlamÄ±ÅŸtÄ±r.
ğŸš€ NasÄ±l Ã‡alÄ±ÅŸtÄ±rÄ±lÄ±r?
Gereksinimler
Projenin Ã§alÄ±ÅŸmasÄ± iÃ§in gerekli baÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kleyin:

bash
Kodu kopyala
pip install -r requirements.txt
AdÄ±mlar
Veri Ã–n Ä°ÅŸleme: src/data_preprocessing.ipynb dosyasÄ±nÄ± Ã§alÄ±ÅŸtÄ±rarak veri yÃ¼kleme ve Ã¶n iÅŸleme iÅŸlemlerini gerÃ§ekleÅŸtirin.
Model EÄŸitimi: src/model_training.ipynb dosyasÄ±nÄ± Ã§alÄ±ÅŸtÄ±rarak modeli eÄŸitin.
SonuÃ§ Analizi: EÄŸitim sonuÃ§larÄ±nÄ± ve gÃ¶rselleri results/ dizininden inceleyin.
ğŸ“‚ Dosya YapÄ±sÄ±
src/data_preprocessing.ipynb: Veri yÃ¼kleme ve Ã¶n iÅŸleme adÄ±mlarÄ±.
src/model_training.ipynb: Modelin eÄŸitilmesi ve deÄŸerlendirilmesi.
requirements.txt: KullanÄ±lan Python kÃ¼tÃ¼phanelerinin listesi.
results/: Model performans gÃ¶rselleri ve Ã§Ä±ktÄ± sonuÃ§larÄ±.
ğŸ”— Veri Seti
Veri setine Cleaned vs Dirty Dataset baÄŸlantÄ±sÄ±ndan ulaÅŸabilirsiniz. Veri seti, aÅŸaÄŸÄ±daki dizinlere yerleÅŸtirilmelidir:

data/train/: EÄŸitim verileri.
data/test/: Test verileri.
data/sample_submission.csv: SÄ±nÄ±f etiketleri dosyasÄ±.
